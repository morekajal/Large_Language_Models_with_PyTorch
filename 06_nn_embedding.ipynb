{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMLz8fGoU8//nPyYS8Xer0a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/morekajal/Large_Language_Models_with_PyTorch/blob/main/06_nn_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### nn.Embedding module gives the embedding vectors of character/words/sentence"
      ],
      "metadata": {
        "id": "VBaSeZWVDjx2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TFUFzQ8aDfnB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize an embedding layer\n",
        "vocab_size = 10000\n",
        "embedding_dim = 100\n",
        "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "#Create some input indices\n",
        "input_indices = torch.LongTensor([1, 5, 3 ,2])\n",
        "\n",
        "#Apply the embedding layer\n",
        "embedded_output = embedding(input_indices)\n",
        "\n",
        "#output_dim = no.of_input, dim_of_embedding_vectors\n",
        "print(embedded_output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqLCOFKYD6H2",
        "outputId": "18915b80-8a7f-457c-823e-d8859a6dd745"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedded_output)\n"
      ],
      "metadata": {
        "id": "ogoTdVa_E140"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[1, 2], [3, 4], [5 ,6]])\n",
        "b = torch.tensor([[7, 8 , 9], [10, 11, 12]])\n",
        "print( a @ b)     #torch dot product"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97gWH1SSFQ5R",
        "outputId": "e7aa3729-cb2e-4703-c22f-df7b51f4f5f5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 27,  30,  33],\n",
            "        [ 61,  68,  75],\n",
            "        [ 95, 106, 117]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# or"
      ],
      "metadata": {
        "id": "ICQAdAnNHNW1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.matmul(a, b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNRe_dHeHWMR",
        "outputId": "a2b5ab2b-e913-4c63-86b7-64d0aefc19b6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 27,  30,  33],\n",
            "        [ 61,  68,  75],\n",
            "        [ 95, 106, 117]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In pytorch for multiplication -> variables should be on same type\n",
        "int_64 = torch.randint(1, (3 ,2))\n",
        "float_32 = torch.rand(2, 3)\n",
        "result = torch.matmul(int_64, float_32)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "6uQ7_yN0HZ6s",
        "outputId": "d18c5692-2182-44af-e769-ec849be57058"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-012b40137c2c>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mint_64\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfloat_32\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat_32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In such cases we can use variable_casting\n",
        "int_64 = torch.randint(1, (3 ,2)).float()\n",
        "float_32 = torch.rand(2, 3)\n",
        "result = torch.matmul(int_64, float_32)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fno5q9_yIa6J",
        "outputId": "5d0678f2-1b35-40be-fec6-4a1861929db4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9QQ7ViC8JRm8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}