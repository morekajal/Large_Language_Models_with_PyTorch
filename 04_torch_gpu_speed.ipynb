{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1puvRZldg2noColNAytyiUzlR6VpZwd9g",
      "authorship_tag": "ABX9TyN93gHAxFXw5zGv+JvBBTWp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/morekajal/Large_Language_Models_with_PyTorch/blob/main/04_torch_gpu_speed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXZAgVz_t491",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44a662ad-6440-401c-8934-cc69d2eb8f63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print (device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "# matrix operation\n",
        "zeros = torch.zeros(1,1)\n",
        "end_time = time.time()\n",
        "\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"{elapsed_time : .4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofs2TAf9uga7",
        "outputId": "8576d026-bfe9-4d0d-8dd2-18e9c83d649f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0.0019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### To check what is better : Numpy on CPU or torch on GPU"
      ],
      "metadata": {
        "id": "YiPqOBMbvTAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch_rand1 = torch.rand(1000, 1000).to(device)\n",
        "torch_rand2 = torch.rand(1000, 1000).to(device)\n",
        "\n",
        "np_rand1 = torch.rand(1000, 1000)\n",
        "np_rand2 = torch.rand(1000, 1000)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "rand = (torch_rand1 @ torch_rand2)\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"torch {elapsed_time : .4f}\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "rand = np.multiply(np_rand1, np_rand2)\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time-start_time\n",
        "print(f\"numpy {elapsed_time : .4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hHWqhCYu908",
        "outputId": "168a85ee-b557-4591-a01c-e6d9a12960f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch  0.5737\n",
            "numpy  0.0026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This above output is for 2 dimenstional - gpu took more time than cpu\n",
        "- But we have many dimentions, [stack of parameters ] -> we can see gpu takes much less time"
      ],
      "metadata": {
        "id": "gViKj01QxHiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch_rand1 = torch.rand(100, 100, 100, 100).to(device)\n",
        "torch_rand2 = torch.rand(100, 100, 100, 100).to(device)\n",
        "\n",
        "np_rand1 = torch.rand(100, 100, 100, 100)\n",
        "np_rand2 = torch.rand(100, 100, 100, 100)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "rand = (torch_rand1 @ torch_rand2)\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"torch {elapsed_time : .4f}\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "rand = np.multiply(np_rand1, np_rand2)\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time-start_time\n",
        "print(f\"numpy {elapsed_time : .4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAU7HEHvwlpg",
        "outputId": "6703a450-c0cb-4d52-d79e-a33f5608aa74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch  0.0003\n",
            "numpy  0.1485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XuL60FYkxjBt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}